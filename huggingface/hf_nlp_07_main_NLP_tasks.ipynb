{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28",
      "authorship_tag": "ABX9TyNqh/zgb/oaphI+DbRAFnUb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7786417af6184ee5ac55f2d9deb44865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2ff33f507a5453f835a889edf6661d4",
              "IPY_MODEL_1a4aa2d1db394a589beac2cbab457970",
              "IPY_MODEL_a57835844b2544ff8faec65b3ce5fdc1"
            ],
            "layout": "IPY_MODEL_b2678b1a81fa4e59b99d0f75c8591bec"
          }
        },
        "c2ff33f507a5453f835a889edf6661d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cc9cb58fbdc4a2b885cc171fb9e49cd",
            "placeholder": "​",
            "style": "IPY_MODEL_1f3b9f78409d4b55b8284fda30b70cc5",
            "value": "Map: 100%"
          }
        },
        "1a4aa2d1db394a589beac2cbab457970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a0abbd70ed542deb3f8cf5e11f15d21",
            "max": 14041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72097b3ef4564bf3a62241b845c0e61e",
            "value": 14041
          }
        },
        "a57835844b2544ff8faec65b3ce5fdc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3739f8064ed9464ea85d3d0fc6df439c",
            "placeholder": "​",
            "style": "IPY_MODEL_9aabe030801146f798e308a67be51b7e",
            "value": " 14041/14041 [00:02&lt;00:00, 5560.86 examples/s]"
          }
        },
        "b2678b1a81fa4e59b99d0f75c8591bec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cc9cb58fbdc4a2b885cc171fb9e49cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f3b9f78409d4b55b8284fda30b70cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a0abbd70ed542deb3f8cf5e11f15d21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72097b3ef4564bf3a62241b845c0e61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3739f8064ed9464ea85d3d0fc6df439c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aabe030801146f798e308a67be51b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14d6a3bb147046a7a5d808590b05e0ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_444ce088319940ae9092130ed97a7069",
              "IPY_MODEL_4d3c7111113440ca976490744af201e8",
              "IPY_MODEL_16856074a1d04561aad4a9626849bb96"
            ],
            "layout": "IPY_MODEL_0fc9df4bf9164d7e9b024b96abec8c67"
          }
        },
        "444ce088319940ae9092130ed97a7069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5de3ea6492de4a2582894746b0e2717e",
            "placeholder": "​",
            "style": "IPY_MODEL_63722540055643028dc194ce4b4e3a14",
            "value": "Map: 100%"
          }
        },
        "4d3c7111113440ca976490744af201e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_737d8e6b10d340c0af5a89d91bb6d50f",
            "max": 3250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b95488305fda47489d6cb686ee82b2bb",
            "value": 3250
          }
        },
        "16856074a1d04561aad4a9626849bb96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec8792985ba9402d938ccc4c15615169",
            "placeholder": "​",
            "style": "IPY_MODEL_7a8a42d519024e3a9e470d0adf639e64",
            "value": " 3250/3250 [00:00&lt;00:00, 5767.20 examples/s]"
          }
        },
        "0fc9df4bf9164d7e9b024b96abec8c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5de3ea6492de4a2582894746b0e2717e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63722540055643028dc194ce4b4e3a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "737d8e6b10d340c0af5a89d91bb6d50f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b95488305fda47489d6cb686ee82b2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec8792985ba9402d938ccc4c15615169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8a42d519024e3a9e470d0adf639e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28ab0d06af2349d99dc13c40c4676b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fca70d32748847cbafee65f69b3d95a0",
              "IPY_MODEL_7d7691212e864c31a1c3cb1bdeb1866e",
              "IPY_MODEL_d61dc367d31a4ce6a9bc15d6dc0bfd4a"
            ],
            "layout": "IPY_MODEL_7a961f9fe7af4a9ab1951dff9b1574f3"
          }
        },
        "fca70d32748847cbafee65f69b3d95a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ca69e4a0f9146178d6a9daae0b61498",
            "placeholder": "​",
            "style": "IPY_MODEL_d6f863aeb3bf4bd9b7c8f4f4f898a4d3",
            "value": "Map: 100%"
          }
        },
        "7d7691212e864c31a1c3cb1bdeb1866e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_722038275ae6456ab22ea7460ece604a",
            "max": 3453,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f850ad816b5b47f8a7517b8c4d2acd2e",
            "value": 3453
          }
        },
        "d61dc367d31a4ce6a9bc15d6dc0bfd4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce585f9e2ccf48e7951e0fc07596b2e0",
            "placeholder": "​",
            "style": "IPY_MODEL_c799402880c64d19bc77ed8cb7714438",
            "value": " 3453/3453 [00:00&lt;00:00, 6516.99 examples/s]"
          }
        },
        "7a961f9fe7af4a9ab1951dff9b1574f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ca69e4a0f9146178d6a9daae0b61498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6f863aeb3bf4bd9b7c8f4f4f898a4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "722038275ae6456ab22ea7460ece604a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f850ad816b5b47f8a7517b8c4d2acd2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce585f9e2ccf48e7951e0fc07596b2e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c799402880c64d19bc77ed8cb7714438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c5a6d01b7004ebc84ba1166d988923f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c5713d5b1444c6faf594892144d47f4",
              "IPY_MODEL_ca87d6b7fd1446acaef2ef5f0c6c57a9",
              "IPY_MODEL_a94b1478dc7f419fad541da3b4c77779"
            ],
            "layout": "IPY_MODEL_ecc1d2f02a0b42b0a44d0406bd9f6064"
          }
        },
        "7c5713d5b1444c6faf594892144d47f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f6eda78cd64620916fb3fd7443d41f",
            "placeholder": "​",
            "style": "IPY_MODEL_fa60b82e2a7e45cc9d64055f90a54109",
            "value": "Downloading builder script: 100%"
          }
        },
        "ca87d6b7fd1446acaef2ef5f0c6c57a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff118e66e3d74a85bf3f2c66e8d4453a",
            "max": 6338,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fe7e4be67584ef98e7e02200a209513",
            "value": 6338
          }
        },
        "a94b1478dc7f419fad541da3b4c77779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d15ccccc34347ffadedd7664cb59e33",
            "placeholder": "​",
            "style": "IPY_MODEL_cffe78ede29d488bb205549b36b513bb",
            "value": " 6.34k/6.34k [00:00&lt;00:00, 86.4kB/s]"
          }
        },
        "ecc1d2f02a0b42b0a44d0406bd9f6064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f6eda78cd64620916fb3fd7443d41f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa60b82e2a7e45cc9d64055f90a54109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff118e66e3d74a85bf3f2c66e8d4453a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fe7e4be67584ef98e7e02200a209513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d15ccccc34347ffadedd7664cb59e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cffe78ede29d488bb205549b36b513bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a629941f42d41d99aedb707bde59a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b13383fe20b346cc9012063e27dbad39",
              "IPY_MODEL_bbcf5c532ca944de8373efe928d5a5d9",
              "IPY_MODEL_f1c3a4e4abe64c81a352ad7ac194bb43"
            ],
            "layout": "IPY_MODEL_b8ffbde0f0fa4370a573977964cc84d9"
          }
        },
        "b13383fe20b346cc9012063e27dbad39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33bbf3dec142407788ca5380f17effe1",
            "placeholder": "​",
            "style": "IPY_MODEL_449b10317ac04cce921d62fc2403b4f1",
            "value": "Map: 100%"
          }
        },
        "bbcf5c532ca944de8373efe928d5a5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b49cb1b07b60400aab5c58210573e288",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b735d9fc5f0749d981b895d596de305e",
            "value": 25000
          }
        },
        "f1c3a4e4abe64c81a352ad7ac194bb43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0232132ed8fa4bab8532ba87aab3eda4",
            "placeholder": "​",
            "style": "IPY_MODEL_8cd7561ec6ec4ae5a1b77115efe28d6e",
            "value": " 25000/25000 [00:30&lt;00:00, 964.97 examples/s]"
          }
        },
        "b8ffbde0f0fa4370a573977964cc84d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33bbf3dec142407788ca5380f17effe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449b10317ac04cce921d62fc2403b4f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b49cb1b07b60400aab5c58210573e288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b735d9fc5f0749d981b895d596de305e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0232132ed8fa4bab8532ba87aab3eda4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cd7561ec6ec4ae5a1b77115efe28d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8db3f207516241e3a67f29709a33a7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_594621d05d244951b53756d955d217c2",
              "IPY_MODEL_066e4f2d855b4e3691fe50bef8ee6033",
              "IPY_MODEL_e60a4daed9d44c66ac0be5e6c57d5bcd"
            ],
            "layout": "IPY_MODEL_0bb4844e3f02496499f418268ca34995"
          }
        },
        "594621d05d244951b53756d955d217c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab6ebb5a78e6479b93a99a682b91aa2b",
            "placeholder": "​",
            "style": "IPY_MODEL_58c595cb439f40d087ca4a8febc344d5",
            "value": "Map: 100%"
          }
        },
        "066e4f2d855b4e3691fe50bef8ee6033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef3c07e1aaab47328b5ce37c0899808f",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a3c8845e66145ea9424acdf3f825f80",
            "value": 25000
          }
        },
        "e60a4daed9d44c66ac0be5e6c57d5bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba5c5ee7adb049a2a066a85a83635f4b",
            "placeholder": "​",
            "style": "IPY_MODEL_e1037904334a45db9e8a3dda9173a5ba",
            "value": " 25000/25000 [01:12&lt;00:00, 356.83 examples/s]"
          }
        },
        "0bb4844e3f02496499f418268ca34995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab6ebb5a78e6479b93a99a682b91aa2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c595cb439f40d087ca4a8febc344d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef3c07e1aaab47328b5ce37c0899808f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a3c8845e66145ea9424acdf3f825f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba5c5ee7adb049a2a066a85a83635f4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1037904334a45db9e8a3dda9173a5ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leoli04/geektime-books/blob/master/huggingface/hf_nlp_07_main_NLP_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 主要的NLP任务"
      ],
      "metadata": {
        "id": "RlLkQp_iGbtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 介绍\n",
        "\n",
        "在本章中，我们将解决以下常见的 NLP 任务：\n",
        "\n",
        "- token分类\n",
        "- 屏蔽语言建模（如 BERT）\n",
        "- 总结\n",
        "- 翻译\n",
        "- 因果语言建模预训练（如 GPT-2）\n",
        "- 问答"
      ],
      "metadata": {
        "id": "sP1ZeCuqGmE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Trainer API 非常适合微调或训练您的模型，而无需担心训练循环期间幕后发生的情况。\n",
        " 使用 Accelerate 可以让您更轻松地自定义您想要的任何部分。"
      ],
      "metadata": {
        "id": "vKeLfvMaHjm5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALuT-YUsGGU-"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "# To run the training on TPU, you will need to uncomment the following line:\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token classification（token 分类）\n",
        "\n",
        "这类任务主要有：\n",
        "\n",
        "- 命名实体识别 (NER)：查找句子中的实体（例如人、位置或组织）\n",
        "- 词性标记（POS）：将句子中的每个单词标记为对应于特定词性（例如名词、动词、形容词等）。\n",
        "- 分块：查找属于同一实体的标记。此任务（可以与 POS 或 NER 组合）可以表述为将一个标签（通常为 B- ）分配给位于块开头的任何标记，另一个标签（通常为 I- ）表示不属于任何块的标记。"
      ],
      "metadata": {
        "id": "jtsVHpPlIAdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 准备数据\n",
        "\n",
        "首先，我们需要一个适合标记分类的数据集。在本节中，我们将使用 CoNLL-2003 数据集，其中包含来自路透社的新闻报道。"
      ],
      "metadata": {
        "id": "lHO-uSUjKVcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### CoNLL-2003 数据集"
      ],
      "metadata": {
        "id": "a3UvtYDhKmKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_datasets = load_dataset(\"conll2003\")\n",
        "\n",
        "raw_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2kjBSxFKpz4",
        "outputId": "8706b37e-9710-46ee-fd32-c82c92accc57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1486: FutureWarning: The repository for conll2003 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/conll2003\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以看到数据集包含我们之前提到的三个任务的标签：NER、POS 和分块。"
      ],
      "metadata": {
        "id": "lxFYaRL94qyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 训查看练集的第一个元素\n",
        "raw_datasets[\"train\"][0][\"tokens\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo9FG5Bo4a4P",
        "outputId": "db9f0db2-0157-42a2-9529-78c23fb32fff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 由于我们想要执行命名实体识别，因此我们将查看 NER 标签：\n",
        "raw_datasets[\"train\"][0][\"ner_tags\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFrJ5Gz_4jZI",
        "outputId": "f78c09ef-c7d8-48a2-9b43-d313db14b5cc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "通过查看数据集的 features 属性来访问这些整数和标签名称之间的对应关系："
      ],
      "metadata": {
        "id": "l9eSy2Zm5IgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
        "ner_feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X191kI2w5Jem",
        "outputId": "6e224afb-2cab-4d19-b874-59736a832344"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "该列包含 ClassLabel 序列的元素。序列元素的类型位于 ner_feature 的 feature 属性中，我们可以通过查看 ner_feature 的 names 属性来访问名称列表 feature ："
      ],
      "metadata": {
        "id": "qwkzhTxQ5Q10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = ner_feature.feature.names\n",
        "label_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i38WZi905R3y",
        "outputId": "7c6a89a8-1fca-4b50-de7a-2d3c99c89f6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "token-classification 管道在前面章节已经看到了这些标签，这里快速回顾一下：\n",
        "\n",
        "- O 表示该单词不对应于任何实体。\n",
        "- B-PER / I-PER 表示该单词对应于人实体的开头/位于人实体内部。\n",
        "- B-ORG / I-ORG 表示该词对应于组织实体的开头/位于组织实体内部。\n",
        "- B-LOC / I-LOC 表示该单词对应于位置实体的开头/位于位置实体内。\n",
        "- B-MISC / I-MISC 表示该单词对应于其他实体的开头/位于其中。"
      ],
      "metadata": {
        "id": "VLaBmE9q5XsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 解码\n",
        "# 查看训练数据0和4索引位置的数据与ner标签\n",
        "for i in (0,4):\n",
        "  words = raw_datasets[\"train\"][i][\"tokens\"]\n",
        "  labels = raw_datasets[\"train\"][i][\"ner_tags\"]\n",
        "\n",
        "  line1 = \"\"\n",
        "  line2 = \"\"\n",
        "  for word, label in zip(words, labels):\n",
        "      full_label = label_names[label]\n",
        "      max_length = max(len(word), len(full_label))\n",
        "      # 单词添加到line1，然后在单词后面添加空格，使得单词和标签的列宽对齐。\n",
        "      line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "      # 将完整标签添加到line2，然后在标签后面添加空格，使得单词和标签的列宽对齐。\n",
        "      line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
        "\n",
        "  print(line1)\n",
        "  print(line2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMJkm6Ex56zn",
        "outputId": "5f9924dd-17bc-484a-855f-782c36fbcd0d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU    rejects German call to boycott British lamb . \n",
            "B-ORG O       B-MISC O    O  O       B-MISC  O    O \n",
            "Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer . \n",
            "B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "正如我们所看到的，跨越两个单词的实体，例如“European Union”和“Werner Zwingmann”，第一个单词被赋予 B- 标签，第二个单词被赋予 I- 标签。"
      ],
      "metadata": {
        "id": "CyGKrtvkTz-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_feature = raw_datasets[\"train\"].features[\"pos_tags\"]\n",
        "label_names_pos = pos_feature.feature.names\n",
        "# 查看训练数据0和4索引位置的数据与标签\n",
        "for i in (0,4):\n",
        "  words = raw_datasets[\"train\"][i][\"tokens\"]\n",
        "  labels = raw_datasets[\"train\"][i][\"pos_tags\"]\n",
        "\n",
        "  line1 = \"\"\n",
        "  line2 = \"\"\n",
        "  for word, label in zip(words, labels):\n",
        "      full_label = label_names_pos[label]\n",
        "      max_length = max(len(word), len(full_label))\n",
        "      # 单词添加到line1，然后在单词后面添加空格，使得单词和标签的列宽对齐。\n",
        "      line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "      # 将完整标签添加到line2，然后在标签后面添加空格，使得单词和标签的列宽对齐。\n",
        "      line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
        "\n",
        "  print(line1)\n",
        "  print(line2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4IeERbqUD_8",
        "outputId": "3b61a42a-4ff0-4d2e-f708-032c22ab8a30"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU  rejects German call to boycott British lamb . \n",
            "NNP VBZ     JJ     NN   TO VB      JJ      NN   . \n",
            "Germany 's  representative to the European Union 's  veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer . \n",
            "NNP     POS NN             TO DT  NNP      NNP   POS JJ         NN        NNP    NNP       VBD  IN NNP       NNS       MD     VB  NN        IN   NNS       JJ    IN   NNP     IN    DT  JJ         NN     VBD JJR     . \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 处理数据"
      ],
      "metadata": {
        "id": "jetLpLMp7NOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "# 创建 tokenizer 对象\n",
        "model_checkpoint = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "iyOYNMbCwzwR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以将 model_checkpoint 替换为您喜欢的 Hub 中的任何其他模型，或者替换为您保存了预训练模型和分词器的本地文件夹。唯一的限制是 tokenizer 需要由 🤗 Tokenizers 库支持，因此有一个“快速”版本可用。您可以在这个[大表](https://huggingface.co/transformers/#supported-frameworks)中看到快速版本的所有架构，并检查您正在使用的 tokenizer 对象是否确实由 🤗 Tokenizers 支持，您可以查看其 is_fast"
      ],
      "metadata": {
        "id": "01fJ8CEtxVaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.is_fast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p0iXQBPxJYb",
        "outputId": "5df9a27b-ec43-466d-97b7-85c9608a2a9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 预标记:将文本转换为token id,便于模型理解\n",
        "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
        "inputs.tokens()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PKcKJEYxlMr",
        "outputId": "e2063bde-d85b-476e-8e67-5ffc99bf5249"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'EU',\n",
              " 'rejects',\n",
              " 'German',\n",
              " 'call',\n",
              " 'to',\n",
              " 'boycott',\n",
              " 'British',\n",
              " 'la',\n",
              " '##mb',\n",
              " '.',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "分词器添加了模型使用的特殊标记（在开头的 [CLS] 和在结尾的 [SEP] ），并保留了大部分单词不变。然而，单词 lamb 被标记为两个子词 la 和 ##mb 。快速分词器可以轻松地将每个分词映射到其相应的单词。"
      ],
      "metadata": {
        "id": "q5oH9iEsVpM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取每个分词映射到其相应的单词，\n",
        "inputs.word_ids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1ROFlB-yz-l",
        "outputId": "6663c708-8dbd-4972-a0d7-8475a482f8d1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们要应用的第一条规则是特殊标记的标签为 -100 。这是因为默认情况下 -100 是一个在我们将使用的损失函数（交叉熵）中被忽略的索引。然后，每个标记都会获得与其内部单词开头的标记相同的标签，因为它们是同一实体的一部分。对于单词内部但不在开头的标记，我们将 B- 替换为 I- （因为标记不开始实体）："
      ],
      "metadata": {
        "id": "KMDp5C7CzHj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels_with_tokens(labels, word_ids):\n",
        "    new_labels = []\n",
        "    current_word = None\n",
        "    for word_id in word_ids:\n",
        "        if word_id != current_word:\n",
        "            # Start of a new word!\n",
        "            current_word = word_id\n",
        "            label = -100 if word_id is None else labels[word_id]\n",
        "            new_labels.append(label)\n",
        "        elif word_id is None:\n",
        "            # Special token\n",
        "            new_labels.append(-100)\n",
        "        else:\n",
        "            # Same word as previous token\n",
        "            label = labels[word_id]\n",
        "            # 如果标签是以B-开头的（标签数值为奇数），则将其转换为以I-开头的标签（数值加1）\n",
        "            # If the label is B-XXX we change it to I-XXX\n",
        "            if label % 2 == 1:\n",
        "                label += 1\n",
        "            new_labels.append(label)\n",
        "\n",
        "    return new_labels"
      ],
      "metadata": {
        "id": "K1-N--F0zJk_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "word_ids = inputs.word_ids()\n",
        "print(labels)\n",
        "print(word_ids)\n",
        "print(align_labels_with_tokens(labels, word_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3AQKmKCzqAb",
        "outputId": "bf90728f-bcb6-48c5-bce4-0a747bd87bda"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
            "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]\n",
            "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "  # 一批数据的的所有token ids\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
        "    )\n",
        "    # 所有的标签\n",
        "    all_labels = examples[\"ner_tags\"]\n",
        "    new_labels = []\n",
        "    for i, labels in enumerate(all_labels):\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = new_labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "b1gAiIh42K9B"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 对数据分批梳理\n",
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets[\"train\"].column_names,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "7786417af6184ee5ac55f2d9deb44865",
            "c2ff33f507a5453f835a889edf6661d4",
            "1a4aa2d1db394a589beac2cbab457970",
            "a57835844b2544ff8faec65b3ce5fdc1",
            "b2678b1a81fa4e59b99d0f75c8591bec",
            "2cc9cb58fbdc4a2b885cc171fb9e49cd",
            "1f3b9f78409d4b55b8284fda30b70cc5",
            "4a0abbd70ed542deb3f8cf5e11f15d21",
            "72097b3ef4564bf3a62241b845c0e61e",
            "3739f8064ed9464ea85d3d0fc6df439c",
            "9aabe030801146f798e308a67be51b7e",
            "14d6a3bb147046a7a5d808590b05e0ef",
            "444ce088319940ae9092130ed97a7069",
            "4d3c7111113440ca976490744af201e8",
            "16856074a1d04561aad4a9626849bb96",
            "0fc9df4bf9164d7e9b024b96abec8c67",
            "5de3ea6492de4a2582894746b0e2717e",
            "63722540055643028dc194ce4b4e3a14",
            "737d8e6b10d340c0af5a89d91bb6d50f",
            "b95488305fda47489d6cb686ee82b2bb",
            "ec8792985ba9402d938ccc4c15615169",
            "7a8a42d519024e3a9e470d0adf639e64",
            "28ab0d06af2349d99dc13c40c4676b35",
            "fca70d32748847cbafee65f69b3d95a0",
            "7d7691212e864c31a1c3cb1bdeb1866e",
            "d61dc367d31a4ce6a9bc15d6dc0bfd4a",
            "7a961f9fe7af4a9ab1951dff9b1574f3",
            "4ca69e4a0f9146178d6a9daae0b61498",
            "d6f863aeb3bf4bd9b7c8f4f4f898a4d3",
            "722038275ae6456ab22ea7460ece604a",
            "f850ad816b5b47f8a7517b8c4d2acd2e",
            "ce585f9e2ccf48e7951e0fc07596b2e0",
            "c799402880c64d19bc77ed8cb7714438"
          ]
        },
        "id": "Fw1YYJQ62Paw",
        "outputId": "729c2c81-2e8d-4e37-c26c-44f3830f1631"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7786417af6184ee5ac55f2d9deb44865"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14d6a3bb147046a7a5d808590b05e0ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28ab0d06af2349d99dc13c40c4676b35"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "通过上面步骤，我们已经完成了数据预处理，并通过tokenize_and_align_labels方法给分词器结果增加了labels属性。labels属性值是通过align_labels_with_tokens处理的，其内部确保了标签与token的一致性，并且将B-XXX转换为I-XXX，以符合BIO（Begin-Inside-Outside）标签体系的规则\n",
        "\n",
        "- B-XXX 表示一个实体的开始。\n",
        "- I-XXX 表示一个实体的内部部分。\n",
        "- O 表示非实体部分。"
      ],
      "metadata": {
        "id": "ttIYcY0KdZlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9TMkwSBdjK6",
        "outputId": "dce7ebe6-f2fd-4868-e9bd-0c14bfdab65a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 14041\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3250\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 3453\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 使用 Trainer API 微调模型"
      ],
      "metadata": {
        "id": "k9V1mHGN5bCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 数据整理"
      ],
      "metadata": {
        "id": "N8OncLNR5tei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们不能像第 3 章那样只使用 DataCollatorWithPadding ，因为它只会填充输入（输入 ID、注意力掩码和令牌类型 ID）。这里我们的标签应该以与输入完全相同的方式填充，以便它们保持相同的大小，使用 -100 作为值，以便在损失计算中忽略相应的预测。这都是由 DataCollatorForTokenClassification 完成的。"
      ],
      "metadata": {
        "id": "HMZx8ZqO6Jfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 数据整理，将每批数据长度填充一致\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "JcC4eqjI5xlo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 测试\n",
        "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
        "batch[\"labels\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHERjXaq567m",
        "outputId": "79b361b6-e003-43c5-95ec-f4c0431b329c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
              "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2):\n",
        "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MucAsIgn6Vj_",
        "outputId": "426000e0-b620-4fd6-d67d-6307d00342c7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n",
            "[-100, 1, 2, -100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 指标"
      ],
      "metadata": {
        "id": "UYSiNKnB7-v_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "为了让 Trainer 在每个时期计算一个指标，我们需要定义一个 compute_metrics() 函数，它接受预测和标签数组，并返回一个包含指标名称和值的字典。"
      ],
      "metadata": {
        "id": "iJMdQGXn-BTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "用于评估 token 分类预测的传统框架是 seqeval。该指标的行为与标准精度不同：它实际上将标签列表视为字符串，而不是整数，因此我们需要在将预测和标签传递给指标之前对其进行完全解码。"
      ],
      "metadata": {
        "id": "_7U-hOgm-IOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Suj591RG-FSt",
        "outputId": "5921f480-cd62-4a64-a393-bda26bc1cb89"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=9327531f5b86a1e80d7ed27650feb8c87f95e50c1f81317714f7559c0687fcb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"seqeval\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8c5a6d01b7004ebc84ba1166d988923f",
            "7c5713d5b1444c6faf594892144d47f4",
            "ca87d6b7fd1446acaef2ef5f0c6c57a9",
            "a94b1478dc7f419fad541da3b4c77779",
            "ecc1d2f02a0b42b0a44d0406bd9f6064",
            "f1f6eda78cd64620916fb3fd7443d41f",
            "fa60b82e2a7e45cc9d64055f90a54109",
            "ff118e66e3d74a85bf3f2c66e8d4453a",
            "8fe7e4be67584ef98e7e02200a209513",
            "6d15ccccc34347ffadedd7664cb59e33",
            "cffe78ede29d488bb205549b36b513bb"
          ]
        },
        "id": "EHbO856P-Mxo",
        "outputId": "4c4630df-9942-49aa-a40f-da09730a5751"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c5a6d01b7004ebc84ba1166d988923f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
        "labels = [label_names[i] for i in labels]\n",
        "print(raw_datasets[\"train\"][0][\"tokens\"])\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_QmwanM-UJ2",
        "outputId": "eff4124d-447a-4521-ff2b-182ed27665ac"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
            "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = labels.copy()\n",
        "predictions[2] = \"O\"\n",
        "metric.compute(predictions=[predictions], references=[labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k9_jHCl_R1i",
        "outputId": "672aab1a-6781-4bf1-c68e-e650a6aa8ebb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MISC': {'precision': 1.0,\n",
              "  'recall': 0.5,\n",
              "  'f1': 0.6666666666666666,\n",
              "  'number': 2},\n",
              " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
              " 'overall_precision': 1.0,\n",
              " 'overall_recall': 0.6666666666666666,\n",
              " 'overall_f1': 0.8,\n",
              " 'overall_accuracy': 0.8888888888888888}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "我们获得每个单独实体以及总体的精度、召回率和 F1 分数。\n",
        "\n",
        "定义一个函数，仅保留总体分数。\n",
        "这个 compute_metrics() 函数首先采用 logits 的 argmax 将它们转换为预测.\n",
        "然后我们必须将标签和预测从整数转换为字符串。我们删除标签为 -100 的所有值，然后将结果传递给 metric.compute() 方法："
      ],
      "metadata": {
        "id": "KmRRQAbI_11J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 仅保留总体分数\n",
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": all_metrics[\"overall_precision\"],\n",
        "        \"recall\": all_metrics[\"overall_recall\"],\n",
        "        \"f1\": all_metrics[\"overall_f1\"],\n",
        "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "UHCWrrri_xcn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 定义模型"
      ],
      "metadata": {
        "id": "mj-aHJRv_-XR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {i: label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}"
      ],
      "metadata": {
        "id": "J18Qt2GsBqB1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfnqQAd8Bwl8",
        "outputId": "767cc543-4a7f-455f-8866-968cfac95903"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.num_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndn4Tld9B18W",
        "outputId": "e59b5d9e-dcf6-4479-87fc-4ea78ce860ad"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 微调模型"
      ],
      "metadata": {
        "id": "aTEa952WB-wX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] -U"
      ],
      "metadata": {
        "id": "RaIxsAdGCX3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "# 定义我们的训练参数\n",
        "args = TrainingArguments(\n",
        "    \"bert-finetuned-ner\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "mgcqaJ_6CFl6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "# 将所有内容传递给 Trainer 并启动训练\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "fxCDQjndC9k_",
        "outputId": "62824c2a-9800-45f7-d070-5b6ddacf4033"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2f6c8fac97ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# 将所有内容传递给 Trainer 并启动训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m trainer = Trainer(\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1526\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_collator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataCollator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_data_collator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdebug_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDebugUnderflowOverflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction_sequence_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceFeatureExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglue_compute_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxnli_compute_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m from .processors import (\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mDataProcessor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mInputExample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/data/processors/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# limitations under the License.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mglue\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglue_convert_examples_to_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglue_output_modes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglue_processors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglue_tasks_num_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msquad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSquadExample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSquadFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSquadV1Processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSquadV2Processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquad_convert_examples_to_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSingleSentenceClassificationProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/data/processors/glue.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m \u001b[0;31m# line: 125\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m \u001b[0;31m# line: 125\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msysconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/tpu/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbfloat16_scope\u001b[0m \u001b[0;31m# line: 69\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_replica_sum\u001b[0m \u001b[0;31m# line: 91\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/tpu/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_cluster_resolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitialize_tpu_system\u001b[0m \u001b[0;31m# line: 25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_cluster_resolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutdown_tpu_system\u001b[0m \u001b[0;31m# line: 26\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/tpu/experimental/embedding/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_embedding_for_serving\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpu_embedding_lookup\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mserving_embedding_lookup\u001b[0m \u001b[0;31m# line: 335\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_embedding_v1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTPUEmbeddingV0\u001b[0m \u001b[0;31m# line: 38\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_embedding_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTPUEmbedding\u001b[0m \u001b[0;31m# line: 75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_embedding_v2_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdagrad\u001b[0m \u001b[0;31m# line: 302\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_embedding_v2_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdagradMomentum\u001b[0m \u001b[0;31m# line: 431\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/tpu/tpu_embedding_v2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdef_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m def _retrieve_variables_impl(\n\u001b[0m\u001b[1;32m   1605\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m     \u001b[0mhosts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mis_in_graph_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIS_IN_GRAPH_MODE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_PRINT_DEPRECATION_WARNINGS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0minvalid_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mnamed_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcallargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeprecated_positions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m           if (spec.position < len(args) and\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/tf_inspect.py\u001b[0m in \u001b[0;36mgetcallargs\u001b[0;34m(*func_and_positional, **named)\u001b[0m\n\u001b[1;32m    317\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcall_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mcall_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0margspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwonlydefaults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwonlydefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcall_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 上传模型\n",
        "trainer.push_to_hub(commit_message=\"Training complete\")"
      ],
      "metadata": {
        "id": "b0n6aqj1ltzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 自定义训练循环"
      ],
      "metadata": {
        "id": "v0m2n8M5DQN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 准备好训练的一切"
      ],
      "metadata": {
        "id": "CwXr673UDYlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=8,\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8\n",
        ")"
      ],
      "metadata": {
        "id": "8dSHVt3aDakK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ")"
      ],
      "metadata": {
        "id": "EvJhwx3dDg5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "# 优化器\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "7OblF7LNDkPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "accelerator = Accelerator()\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, eval_dataloader\n",
        ")"
      ],
      "metadata": {
        "id": "071s25dnDo0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "\n",
        "num_train_epochs = 3\n",
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ],
      "metadata": {
        "id": "tFnXxpc1DwxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_scheduler\n",
        "# 将我们的模型推送到中心\n",
        "num_train_epochs = 3\n",
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ],
      "metadata": {
        "id": "jZw-SGsBD2zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 克隆存储库到本地文件夹\n",
        "output_dir = \"bert-finetuned-ner-accelerate\"\n",
        "repo = Repository(output_dir, clone_from=repo_name)"
      ],
      "metadata": {
        "id": "LfZRRFZbD6O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们可以通过调用 repo.push_to_hub() 方法上传保存在 output_dir 中的任何内容。"
      ],
      "metadata": {
        "id": "cRbuHTwqESeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 训练循环"
      ],
      "metadata": {
        "id": "F-_BbZAPEVWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess(predictions, labels):\n",
        "    predictions = predictions.detach().cpu().clone().numpy()\n",
        "    labels = labels.detach().cpu().clone().numpy()\n",
        "\n",
        "    # Remove ignored index (special tokens) and convert to labels\n",
        "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    return true_labels, true_predictions"
      ],
      "metadata": {
        "id": "UC5GXIUKEYsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "定义进度条以跟踪训练的进行情况后，循环分为三个部分：\n",
        "- 训练本身是对 train_dataloader 的经典迭代，向前传递模型，然后向后传递和优化器步骤。\n",
        "- 评估，在批量获得模型的输出后有一个新颖之处：由于两个进程可能将输入和标签填充到不同的形状，因此我们需要使用 accelerator.pad_across_processes() 进行预测和在调用 gather() 方法之前标记相同的形状。如果我们不这样做，评估要么会出错，要么永远挂起。然后，我们将结果发送到 metric.add_batch() 并在评估循环结束后调用 metric.compute() 。\n",
        "- 保存和上传，我们首先保存模型和分词器，然后调用 repo.push_to_hub() 。请注意，我们使用参数 blocking=False 告诉 🤗 Hub 库推送异步进程。这样，训练就可以正常继续，并且该（长）指令在后台执行。"
      ],
      "metadata": {
        "id": "zsgI-OrxEjnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "训练循环的完整代码："
      ],
      "metadata": {
        "id": "FiVSs58VFIbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "for epoch in range(num_train_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    for batch in eval_dataloader:\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        predictions = outputs.logits.argmax(dim=-1)\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        # Necessary to pad predictions and labels for being gathered\n",
        "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
        "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
        "\n",
        "        predictions_gathered = accelerator.gather(predictions)\n",
        "        labels_gathered = accelerator.gather(labels)\n",
        "\n",
        "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
        "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
        "\n",
        "    results = metric.compute()\n",
        "    print(\n",
        "        f\"epoch {epoch}:\",\n",
        "        {\n",
        "            key: results[f\"overall_{key}\"]\n",
        "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # Save and upload\n",
        "    accelerator.wait_for_everyone()\n",
        "    unwrapped_model = accelerator.unwrap_model(model)\n",
        "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
        "    if accelerator.is_main_process:\n",
        "        tokenizer.save_pretrained(output_dir)\n",
        "        repo.push_to_hub(\n",
        "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
        "        )"
      ],
      "metadata": {
        "id": "_9Sqru0UE6TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 🤗 Accelerate 保存的模型说明："
      ],
      "metadata": {
        "id": "-k5WDejEFnVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 告诉所有进程等到每个人都处于该阶段后再继续。这是为了确保在保存之前我们在每个过程中都有相同的模型。\n",
        "accelerator.wait_for_everyone()\n",
        "# 然后我们获取 unwrapped_model ，这是我们定义的基本模型。\n",
        "unwrapped_model = accelerator.unwrap_model(model)\n",
        "unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)"
      ],
      "metadata": {
        "id": "VsIPps-4FMps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 使用微调模型"
      ],
      "metadata": {
        "id": "3rGq7MPVFAPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Replace this with your own checkpoint\n",
        "model_checkpoint = \"huggingface-course/bert-finetuned-ner\"\n",
        "token_classifier = pipeline(\n",
        "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
        ")\n",
        "token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
      ],
      "metadata": {
        "id": "0kl5s43rFD9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 微调masked语言模型"
      ],
      "metadata": {
        "id": "3N7ph3F-t9OW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install accelerate\n",
        "# To run the training on TPU, you will need to uncomment the following line:\n",
        "# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
        "!apt install git-lfs"
      ],
      "metadata": {
        "id": "ZgBeQ98O8PJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch] -U"
      ],
      "metadata": {
        "id": "5JFNW2hXgWLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在某些情况下，您需要在训练特定任务的 head 之前先对数据上的语言模型进行微调。例如，如果您的数据集包含法律合同或科学文章，像 BERT 这样的普通 Transformer 模型通常会将语料库中的特定领域单词视为稀有标记，并且最终的性能可能不太令人满意。通过对域内数据微调语言模型，您可以提高许多下游任务的性能，这意味着您通常只需执行此步骤一次！\n",
        "\n",
        "在域内数据上微调预训练语言模型的过程通常称为域适应。"
      ],
      "metadata": {
        "id": "4zSSp4gMuJyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 选择用于掩码语言建模的预训练模型\n",
        "\n",
        "在Hugging Face Hub可以通过选择“Fill-Mask” 过滤。\n",
        "\n",
        "尽管 BERT 和 RoBERTa 系列模型的下载量最多，但我们将使用名为 DistilBERT 的模型，该模型可以更快地训练，并且下游性能几乎没有损失。该模型使用一种称为知识蒸馏的特殊技术进行训练，其中使用像 BERT 这样的大型“教师模型”来指导参数少得多的“学生模型”的训练。"
      ],
      "metadata": {
        "id": "UeHssyCMuU8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMaskedLM\n",
        "# 下载模型\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "24FLpdesu2-l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们可以通过调用 num_parameters() 方法来查看这个模型有多少个参数："
      ],
      "metadata": {
        "id": "0HurKccMvJpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DistilBERT 拥有大约 6700 万个参数，大约比 BERT 基础模型小两倍，这大致意味着训练速度提高了两倍"
      ],
      "metadata": {
        "id": "d0IoQ4IFvWLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distilbert_num_parameters = model.num_parameters() / 1_000_000\n",
        "print(f\"'>>> DistilBERT number of parameters: {round(distilbert_num_parameters)}M'\")\n",
        "print(f\"'>>> BERT number of parameters: 110M'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP6imZmDvIzF",
        "outputId": "a7a99d74-3be8-469c-9775-d9b93cff9b8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'>>> DistilBERT number of parameters: 67M'\n",
            "'>>> BERT number of parameters: 110M'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "# 加载 DistilBERT 的分词器\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "hV4fOW3CviMs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"This is a great [MASK].\""
      ],
      "metadata": {
        "id": "VT4e5xiavgLg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "token_logits = model(**inputs).logits\n",
        "print(token_logits)\n",
        "# Find the location of [MASK] and extract its logits\n",
        "# torch.where返回两个值：第一个值是满足条件的行索引，第二个值是满足条件的列索引。\n",
        "# 由于inputs[\"input_ids\"]是一个二维张量，我们只需要列索引（索引为1），因此使用[1]来获取。\n",
        "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
        "# 取批次的第一个元素，然后取mask_token_index指定的[MASK]标记的logits，最后[:]表示取这个位置的所有词汇表logits。\n",
        "mask_token_logits = token_logits[0, mask_token_index, :]\n",
        "print(mask_token_logits)\n",
        "# Pick the [MASK] candidates with the highest logits\n",
        "# 使用torch.topk函数来找到mask_token_logits中最高的5个logits值。\n",
        "# indices属性包含了每个序列位置的top-k索引值，使用[0]来获取第一个批次的索引，使用tolist()将索引张量转换为Python列表\n",
        "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
        "\n",
        "for token in top_5_tokens:\n",
        "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raSq3xtSvugT",
        "outputId": "0a95136d-e771-4e9c-ac28-88108f451a54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ -5.5882,  -5.5868,  -5.5958,  ...,  -4.9448,  -4.8174,  -2.9905],\n",
            "         [-11.9031, -11.8872, -12.0623,  ..., -10.9570, -10.6464,  -8.6324],\n",
            "         [-11.9604, -12.1520, -12.1278,  ..., -10.0218,  -8.6074,  -8.0971],\n",
            "         ...,\n",
            "         [ -4.8228,  -4.6268,  -5.1041,  ...,  -4.2771,  -5.0184,  -3.9428],\n",
            "         [-11.2945, -11.2388, -11.3857,  ...,  -9.2063,  -9.3411,  -6.1505],\n",
            "         [ -9.5213,  -9.4632,  -9.5022,  ...,  -8.6561,  -8.4908,  -4.6903]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-4.8228, -4.6268, -5.1041,  ..., -4.2771, -5.0184, -3.9428]],\n",
            "       grad_fn=<IndexBackward0>)\n",
            "'>>> This is a great deal.'\n",
            "'>>> This is a great success.'\n",
            "'>>> This is a great adventure.'\n",
            "'>>> This is a great idea.'\n",
            "'>>> This is a great feat.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 数据集"
      ],
      "metadata": {
        "id": "l_4apXB87_BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "# 加载数据集\n",
        "imdb_dataset = load_dataset(\"imdb\")\n",
        "imdb_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Smt_XlSa8FBo",
        "outputId": "7207d388-da32-4deb-99ad-15ffd14866a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = imdb_dataset[\"train\"].shuffle(seed=42).select(range(3))\n",
        "\n",
        "for row in sample:\n",
        "    print(f\"\\n'>>> Review: {row['text']}'\")\n",
        "    print(f\"'>>> Label: {row['label']}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeM59lnR9VWc",
        "outputId": "3462bda2-b100-4e61-92cf-6ae769c08ba1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'>>> Review: There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier's plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it's the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...'\n",
            "'>>> Label: 1'\n",
            "\n",
            "'>>> Review: This movie is a great. The plot is very true to the book which is a classic written by Mark Twain. The movie starts of with a scene where Hank sings a song with a bunch of kids called \"when you stub your toe on the moon\" It reminds me of Sinatra's song High Hopes, it is fun and inspirational. The Music is great throughout and my favorite song is sung by the King, Hank (bing Crosby) and Sir \"Saggy\" Sagamore. OVerall a great family movie or even a great Date movie. This is a movie you can watch over and over again. The princess played by Rhonda Fleming is gorgeous. I love this movie!! If you liked Danny Kaye in the Court Jester then you will definitely like this movie.'\n",
            "'>>> Label: 1'\n",
            "\n",
            "'>>> Review: George P. Cosmatos' \"Rambo: First Blood Part II\" is pure wish-fulfillment. The United States clearly didn't win the war in Vietnam. They caused damage to this country beyond the imaginable and this movie continues the fairy story of the oh-so innocent soldiers. The only bad guys were the leaders of the nation, who made this war happen. The character of Rambo is perfect to notice this. He is extremely patriotic, bemoans that US-Americans didn't appreciate and celebrate the achievements of the single soldier, but has nothing but distrust for leading officers and politicians. Like every film that defends the war (e.g. \"We Were Soldiers\") also this one avoids the need to give a comprehensible reason for the engagement in South Asia. And for that matter also the reason for every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \"Do we get to win this time?\" Yes, you do.'\n",
            "'>>> Label: 0'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 预处理数据"
      ],
      "metadata": {
        "id": "T_xiAXvMTxI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "对于自回归和掩码语言模型，常见的预处理步骤是连接所有示例，然后将整个语料库分割成大小相等的块。把所有东西连接在一起原因是，如果单个示例太长，则可能会被截断，这将导致丢失可能对语言建模任务有用的信息！\n",
        "\n",
        "所以，首先，我们将像往常一样首先对语料库进行标记，但不在标记生成器中设置 truncation=True 选项。"
      ],
      "metadata": {
        "id": "OeA-Wyn3UB8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取\n",
        "def tokenize_function(examples):\n",
        "    result = tokenizer(examples[\"text\"])\n",
        "    if tokenizer.is_fast:\n",
        "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
        "    return result\n",
        "\n",
        "\n",
        "# Use batched=True to activate fast multithreading!\n",
        "tokenized_datasets = imdb_dataset.map(\n",
        "    tokenize_function, batched=True, remove_columns=[\"text\", \"label\"]\n",
        ")\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "5a629941f42d41d99aedb707bde59a73",
            "b13383fe20b346cc9012063e27dbad39",
            "bbcf5c532ca944de8373efe928d5a5d9",
            "f1c3a4e4abe64c81a352ad7ac194bb43",
            "b8ffbde0f0fa4370a573977964cc84d9",
            "33bbf3dec142407788ca5380f17effe1",
            "449b10317ac04cce921d62fc2403b4f1",
            "b49cb1b07b60400aab5c58210573e288",
            "b735d9fc5f0749d981b895d596de305e",
            "0232132ed8fa4bab8532ba87aab3eda4",
            "8cd7561ec6ec4ae5a1b77115efe28d6e"
          ]
        },
        "id": "mjRWK9cVUqaq",
        "outputId": "a1c17602-37d7-4698-c1be-63251f8f3b0d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a629941f42d41d99aedb707bde59a73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (532 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
              "        num_rows: 25000\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "现在我们已经对电影评论进行了标记，下一步是将它们组合在一起并将结果分成多个块。可以通过检查分词器的 model_max_length 属性来推断块大小"
      ],
      "metadata": {
        "id": "nOvCuGZCXQwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIuJC4OdXbqY",
        "outputId": "fa634845-1527-48a2-e078-aa19aaf749cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 128"
      ],
      "metadata": {
        "id": "T8Aq4zp4X5Oj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing produces a list of lists for each feature\n",
        "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
        "\n",
        "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
        "    print(f\"'>>> Review {idx} length: {len(sample)}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km2LzBA2YfT1",
        "outputId": "b29b91b9-6798-4707-b0eb-d4133fe12ffd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'>>> Review 0 length: 363'\n",
            "'>>> Review 1 length: 304'\n",
            "'>>> Review 2 length: 133'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concatenated_examples = {\n",
        "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
        "}\n",
        "total_length = len(concatenated_examples[\"input_ids\"])\n",
        "print(f\"'>>> Concatenated reviews length: {total_length}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs-EYCL2YdYS",
        "outputId": "c71a1d6a-abdf-4246-c59b-666e65fd6637"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'>>> Concatenated reviews length: 800'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = {\n",
        "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
        "    for k, t in concatenated_examples.items()\n",
        "}\n",
        "\n",
        "for chunk in chunks[\"input_ids\"]:\n",
        "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWaiXWXDZV_0",
        "outputId": "54e43e50-6bbb-40a1-86c2-d275bd8bbcbb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 128'\n",
            "'>>> Chunk length: 32'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "正如您在此示例中所看到的，最后一个块通常会小于最大块大小。处理这个问题有两种主要策略：\n",
        "- 如果最后一个块小于 chunk_size ，则删除它。\n",
        "- 填充最后一个块，直到其长度等于 chunk_size 。\n",
        "\n",
        "我们将在这里采用第一种方法，所以让我们将上述所有逻辑包装在一个函数中，我们可以将其应用于标记化数据集："
      ],
      "metadata": {
        "id": "qYqH3QpSa7DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def group_texts(examples):\n",
        "    # Concatenate all texts\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    # Compute length of concatenated texts\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the last chunk if it's smaller than chunk_size\n",
        "    total_length = (total_length // chunk_size) * chunk_size\n",
        "    # Split by chunks of max_len\n",
        "    result = {\n",
        "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    # Create a new labels column\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ],
      "metadata": {
        "id": "68w3ZP-WbKMD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在 group_texts() 的最后一步中，我们创建了一个新的 labels 列，它是 input_ids 列的副本。正如我们很快就会看到的，这是因为在屏蔽语言模型中，目标是预测输入批次中的随机屏蔽标记，并且通过创建 labels 列，我们为我们的语言模型提供了可供学习的基本事实。"
      ],
      "metadata": {
        "id": "VDIvWoAzc6VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
        "lm_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292,
          "referenced_widgets": [
            "8db3f207516241e3a67f29709a33a7ec",
            "594621d05d244951b53756d955d217c2",
            "066e4f2d855b4e3691fe50bef8ee6033",
            "e60a4daed9d44c66ac0be5e6c57d5bcd",
            "0bb4844e3f02496499f418268ca34995",
            "ab6ebb5a78e6479b93a99a682b91aa2b",
            "58c595cb439f40d087ca4a8febc344d5",
            "ef3c07e1aaab47328b5ce37c0899808f",
            "8a3c8845e66145ea9424acdf3f825f80",
            "ba5c5ee7adb049a2a066a85a83635f4b",
            "e1037904334a45db9e8a3dda9173a5ba"
          ]
        },
        "id": "dQe4XdEPc0Ys",
        "outputId": "67273212-1949-43ef-db12-04d6905bd742"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8db3f207516241e3a67f29709a33a7ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
              "        num_rows: 61291\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
              "        num_rows: 59904\n",
              "    })\n",
              "    unsupervised: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
              "        num_rows: 122957\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "gA2dW12hdRw6",
        "outputId": "fed403f9-f8f1-47e1-805a-2b381b8062c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"as the vietnam war and race issues in the united states. in between asking politicians and ordinary denizens of stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men. < br / > < br / > what kills me about i am curious - yellow is that 40 years ago, this was considered pornographic. really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. while my countrymen mind find it shocking, in reality sex and nudity are a major staple in swedish cinema. even ingmar bergman,\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 使用 Trainer API 微调 DistilBERT"
      ],
      "metadata": {
        "id": "DV189VhhdVcO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "🤗 Transformers 专门为这项任务准备了一个 DataCollatorForLanguageModeling 。我们只需向它传递标记生成器和一个 mlm_probability 参数，该参数指定要屏蔽的标记的部分。我们选择 15%，这是 BERT 使用的数量，也是文献中的常见选择"
      ],
      "metadata": {
        "id": "2F3nAinedqZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
      ],
      "metadata": {
        "id": "gCWsoCTgdaWq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 了解随机屏蔽的工作原理\n",
        "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
        "for sample in samples:\n",
        "    _ = sample.pop(\"word_ids\")\n",
        "\n",
        "for chunk in data_collator(samples)[\"input_ids\"]:\n",
        "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Zu7pZmueNua",
        "outputId": "83ae2b47-e485-434e-ebb9-c737e78bc35e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'>>> [CLS] [MASK] rented i am curious [MASK] yellow from my video store because of all the controversy that surrounded it when it [MASK] first released in 1967. i also heard that at first it was seized by u. s. customs if it ever tried to enter this country, therefore being [unused154] fan of films considered \" controversial \" i really had to see this for myself. < br / > < br restrict > the plot is centered around a young swedish drama student named lena who wants to learn [MASK] she can [MASK] life. in [MASK] she wants to focus her attentions to making some sort of documentary on what the average [MASK]ede thought about certain political issues [MASK]'\n",
            "\n",
            "'>>> as the vietnam war and race [MASK] [MASK] the united states. in between asking politicians and ordinary den [MASK]ns of stockholm about their [MASK] on [MASK], she [MASK] sex with her drama [MASK], classmates, and married men. < br / > < [MASK] / > what kills resurrected about i am curious - yellow is that 40 years ago, this was considered pornographic. [MASK], the sex and nudity scenes are few and far between, even then [MASK]'[MASK] not shot like some [MASK]ly [MASK] porno. while my countrymen mind find it shocking, in reality [MASK] and nudity are a major staple in swedish cinema. even ing [MASK] bergman,'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "在训练用于屏蔽语言建模的模型时，可以使用的一种技术是将整个单词屏蔽在一起，而不仅仅是单个标记。这种方法称为全字屏蔽。如果我们想使用全字屏蔽，我们需要自己构建一个数据整理器。数据整理器只是一个函数，它获取样本列表并将它们转换为批处理"
      ],
      "metadata": {
        "id": "EIWyAmD8fRVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "from transformers import default_data_collator\n",
        "\n",
        "wwm_probability = 0.2\n",
        "\n",
        "\n",
        "def whole_word_masking_data_collator(features):\n",
        "    for feature in features:\n",
        "        word_ids = feature.pop(\"word_ids\")\n",
        "\n",
        "        # Create a map between words and corresponding token indices\n",
        "        mapping = collections.defaultdict(list)\n",
        "        current_word_index = -1\n",
        "        current_word = None\n",
        "        for idx, word_id in enumerate(word_ids):\n",
        "            if word_id is not None:\n",
        "                if word_id != current_word:\n",
        "                    current_word = word_id\n",
        "                    current_word_index += 1\n",
        "                mapping[current_word_index].append(idx)\n",
        "\n",
        "        # Randomly mask words\n",
        "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
        "        input_ids = feature[\"input_ids\"]\n",
        "        labels = feature[\"labels\"]\n",
        "        new_labels = [-100] * len(labels)\n",
        "        for word_id in np.where(mask)[0]:\n",
        "            word_id = word_id.item()\n",
        "            for idx in mapping[word_id]:\n",
        "                new_labels[idx] = labels[idx]\n",
        "                input_ids[idx] = tokenizer.mask_token_id\n",
        "        feature[\"labels\"] = new_labels\n",
        "\n",
        "    return default_data_collator(features)"
      ],
      "metadata": {
        "id": "EqpREY5AfTi5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
        "batch = whole_word_masking_data_collator(samples)\n",
        "\n",
        "for chunk in batch[\"input_ids\"]:\n",
        "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKCM1GVHfcPf",
        "outputId": "1f9c9f7b-8670-4b1b-9554-743d379c6779"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'>>> [CLS] [MASK] rented i am curious - yellow from my video [MASK] because [MASK] [MASK] the controversy that [MASK] it when it was first released in 1967 [MASK] i [MASK] [MASK] that [MASK] first [MASK] was seized by u [MASK] [MASK] [MASK] customs if it ever tried to enter this country, [MASK] being a fan of films [MASK] \" controversial \" i really had to see this for myself. < br / > < br / > the plot is centered around a [MASK] [MASK] [MASK] student named lena [MASK] wants to learn everything she can [MASK] life. in particular she wants to focus her attentions to making some sort of [MASK] on [MASK] the average swede thought about certain [MASK] issues such'\n",
            "\n",
            "'>>> as the vietnam war and [MASK] issues in [MASK] united states. in [MASK] asking politicians and ordinary denizens [MASK] stockholm about their opinions on politics [MASK] [MASK] has sex with her drama teacher [MASK] [MASK], and [MASK] men [MASK] < br / [MASK] < br / > [MASK] kills me about [MASK] am curious - yellow is that 40 years ago, this was considered pornographic [MASK] really, the sex and nudity [MASK] [MASK] [MASK] and [MASK] between, even then it'[MASK] [MASK] shot [MASK] [MASK] cheaply made porno [MASK] while my countrymen mind find it shocking [MASK] in reality sex and nudity are [MASK] major staple in swedish cinema. even ingmar [MASK] [MASK]'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 缩小数据集大小：\n",
        "# 自动创建新的 train 和 test 分割，训练集大小设置为 10,000 个示例，验证集设置为其中的 10%\n",
        "train_size = 10_000\n",
        "test_size = int(0.1 * train_size)\n",
        "\n",
        "downsampled_dataset = lm_datasets[\"train\"].train_test_split(\n",
        "    train_size=train_size, test_size=test_size, seed=42\n",
        ")\n",
        "downsampled_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqvwpvlMfwMl",
        "outputId": "dd3ef882-e96e-4299-8792-cbd8882da144"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
              "        num_rows: 1000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 64\n",
        "# Show the training loss with every epoch\n",
        "logging_steps = len(downsampled_dataset[\"train\"]) // batch_size\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"{model_name}-finetuned-imdb\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    push_to_hub=True,\n",
        "    fp16=True,\n",
        "    logging_steps=logging_steps,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEBhkfqKgDZ3",
        "outputId": "6fa9b2b6-fbe9-4a51-b12e-aa1046626f99"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " logging_steps 以确保我们跟踪每个时期的训练损失\n",
        " fp16=True 来启用混合精度训练\n",
        "\n",
        " 如果您使用全字屏蔽整理器，还需要设置 remove_unused_columns=False 以确保我们在训练期间不会丢失 word_ids 列"
      ],
      "metadata": {
        "id": "hXSLp5xBhfea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=downsampled_dataset[\"train\"],\n",
        "    eval_dataset=downsampled_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "id": "Bm_iWJs3iCRp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "N_M1ShEsieiK",
        "outputId": "4c9c187b-7129-43df-87a5-fb5a2271db00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 50/471 1:02:48 < 9:10:55, 0.01 it/s, Epoch 0.31/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 语言模型的困惑\n",
        "\n",
        "与文本分类或问答等其他任务不同，我们需要使用带标签的语料库进行训练，而语言建模则没有任何明确的标签。那么我们如何确定什么才是好的语言模型呢？\n",
        "\n",
        "困惑度有多种数学定义，但我们将使用的定义为交叉熵损失的指数。因此，我们可以通过使用 Trainer.evaluate() 函数计算测试集上的交叉熵损失，然后取结果的指数来计算预训练模型的困惑度：\n",
        "\n",
        "较低的困惑度分数意味着更好的语言模型。"
      ],
      "metadata": {
        "id": "99Hfhf0FjBDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算测试集上产生的困惑度\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
      ],
      "metadata": {
        "id": "maz2Z9bWit9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 使用 🤗 Accelerate 微调 DistilBERT"
      ],
      "metadata": {
        "id": "Oi_Xrzbqi4aX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "，我们看到 DataCollatorForLanguageModeling 还在每次评估中应用随机掩蔽，因此每次训练运行时我们都会看到困惑度分数出现一些波动。消除这种随机性来源的一种方法是在整个测试集上应用一次屏蔽，然后使用 🤗 Transformers 中的默认数据整理器在评估期间收集批次。"
      ],
      "metadata": {
        "id": "4smXUSZzkegf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_random_mask(batch):\n",
        "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
        "    masked_inputs = data_collator(features)\n",
        "    # Create a new \"masked\" column for each column in the dataset\n",
        "    return {\"masked_\" + k: v.numpy() for k, v in masked_inputs.items()}"
      ],
      "metadata": {
        "id": "UHV0bcHXkgdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "downsampled_dataset = downsampled_dataset.remove_columns([\"word_ids\"])\n",
        "eval_dataset = downsampled_dataset[\"test\"].map(\n",
        "    insert_random_mask,\n",
        "    batched=True,\n",
        "    remove_columns=downsampled_dataset[\"test\"].column_names,\n",
        ")\n",
        "eval_dataset = eval_dataset.rename_columns(\n",
        "    {\n",
        "        \"masked_input_ids\": \"input_ids\",\n",
        "        \"masked_attention_mask\": \"attention_mask\",\n",
        "        \"masked_labels\": \"labels\",\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "FH51xZVpkjkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 数据加载器，使用 🤗 Transformers 中的 default_data_collator 作为评估集：\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import default_data_collator\n",
        "\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(\n",
        "    downsampled_dataset[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_dataset, batch_size=batch_size, collate_fn=default_data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "XPwk7omtkox3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载预训练模型的新版本\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n"
      ],
      "metadata": {
        "id": "Tjhg_n64kuG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "# 优化器\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "Kfb_LcpSkxky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "# 使用 Accelerator 对象进行训练 内容准备\n",
        "accelerator = Accelerator()\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, eval_dataloader\n",
        ")"
      ],
      "metadata": {
        "id": "hYQitTlwk5aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 指定学习率调度程序\n",
        "from transformers import get_scheduler\n",
        "\n",
        "num_train_epochs = 3\n",
        "num_update_steps_per_epoch = len(train_dataloader)\n",
        "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps,\n",
        ")"
      ],
      "metadata": {
        "id": "uG3yPtirk96W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在 Hugging Face Hub 上创建模型存储库\n",
        "from huggingface_hub import get_full_repo_name\n",
        "\n",
        "model_name = \"distilbert-base-uncased-finetuned-imdb-accelerate\"\n",
        "repo_name = get_full_repo_name(model_name)\n",
        "repo_name"
      ],
      "metadata": {
        "id": "w44hX_gWlCzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import Repository\n",
        "# 使用 🤗 Hub 中的 Repository 类创建并克隆存储库\n",
        "output_dir = model_name\n",
        "repo = Repository(output_dir, clone_from=repo_name)"
      ],
      "metadata": {
        "id": "OwJc2NlulITh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import math\n",
        "# 循环训练与评估\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "for epoch in range(num_train_epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        losses.append(accelerator.gather(loss.repeat(batch_size)))\n",
        "\n",
        "    losses = torch.cat(losses)\n",
        "    losses = losses[: len(eval_dataset)]\n",
        "    try:\n",
        "        perplexity = math.exp(torch.mean(losses))\n",
        "    except OverflowError:\n",
        "        perplexity = float(\"inf\")\n",
        "\n",
        "    print(f\">>> Epoch {epoch}: Perplexity: {perplexity}\")\n",
        "\n",
        "    # Save and upload\n",
        "    accelerator.wait_for_everyone()\n",
        "    unwrapped_model = accelerator.unwrap_model(model)\n",
        "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
        "    if accelerator.is_main_process:\n",
        "        tokenizer.save_pretrained(output_dir)\n",
        "        repo.push_to_hub(\n",
        "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
        "        )"
      ],
      "metadata": {
        "id": "h4YpCGDolMHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 使用我们微调的模型"
      ],
      "metadata": {
        "id": "D6peJzAWlTL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "mask_filler = pipeline(\n",
        "    \"fill-mask\", model=\"huggingface-course/distilbert-base-uncased-finetuned-imdb\"\n",
        ")"
      ],
      "metadata": {
        "id": "4lYK0W87lVc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = mask_filler(text)\n",
        "\n",
        "for pred in preds:\n",
        "    print(f\">>> {pred['sequence']}\")"
      ],
      "metadata": {
        "id": "k-8Y37UxlXXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 翻译\n",
        "\n",
        "这是另一个序列到序列的任务，这意味着它是一个可以表述为从一个序列到另一个序列的问题。从这个意义上说，这个问题非常接近总结，您可以将我们在这里看到的内容应用于其他序列到序列的问题，例如：\n",
        "\n",
        "- 风格迁移：创建一个模型，将某种风格的文本翻译成另一种风格（例如，正式英语翻译成休闲英语，或者莎士比亚英语翻译成现代英语）\n",
        "\n",
        "- 生成式问答：创建一个模型，根据给定的上下文生成问题的答案"
      ],
      "metadata": {
        "id": "e0DrhH-0s71_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在本节中，我们将在 KDE4 数据集（KDE 应用程序的本地化文件数据集）上微调预训练的 Marian 模型，以将其从英语翻译为法语（因为许多 Hugging Face 员工都说这两种语言）。"
      ],
      "metadata": {
        "id": "XZtux2bntYxV"
      }
    }
  ]
}